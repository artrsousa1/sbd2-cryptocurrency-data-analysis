{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "232cf38d",
   "metadata": {},
   "source": [
    "# ETL\n",
    "\n",
    "O processo de ETL (Extract, Transform, Load) é uma parte crucial na análise do nosso Dataset. Ele nos permite extrair dados brutos, transformá-los em um formato adequado para análise e carregá-los em um sistema de armazenamento eficiente.\n",
    "\n",
    "Nesse sentido, para implementar o processo de ETL, utilizamos um notebook Jupyter para facilitar a manipulação e visualização dos dados. O notebook está estruturado em três etapas principais:\n",
    "\n",
    "1. **Extração (Extract)**: Nesta etapa, utilizaremos os dados brutos da camada raw. Utilizamos bibliotecas como `pandas` para ler e carregar os dados brutos.\n",
    "\n",
    "2. **Transformação (Transform)**: Após a extração, os dados passam por um processo de limpeza e transformação. Isso inclui a remoção de duplicatas, preenchimento de valores ausentes e a aplicação de transformações de tipo, como conversão de tipos de dados e normalização.\n",
    "\n",
    "3. **Carga (Load)**: Por fim, após o tratamento dos dados, o script vai criar um DDL para criar a tabela na camada silver e carregar os dados transformados nela."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd94e2f",
   "metadata": {},
   "source": [
    "## 1. Extração (Extract)\n",
    "\n",
    "Nesta primeira etapa, realizamos a extração dos dados brutos da camada raw.\n",
    "Utilizamos a biblioteca Pandas para ler o arquivo CSV com os dados brutos e carregá-lo em um DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1787df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "raw_path = Path('../data/raw/currencies_data.csv')\n",
    "silver_path = Path('../data/silver/silver_currencies_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5a727",
   "metadata": {},
   "source": [
    "É possível visualizar abaixo os tipos de dados presentes no DataFrame após a extração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a57bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 446176 entries, 0 to 446175\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   cmcRank                   446176 non-null  int64  \n",
      " 1   name                      446176 non-null  object \n",
      " 2   symbol                    446176 non-null  object \n",
      " 3   marketPairCount           446176 non-null  int64  \n",
      " 4   circulatingSupply         446176 non-null  float64\n",
      " 5   totalSupply               446176 non-null  float64\n",
      " 6   maxSupply                 347894 non-null  float64\n",
      " 7   isActive                  446176 non-null  int64  \n",
      " 8   lastUpdated               446176 non-null  object \n",
      " 9   dateAdded                 446176 non-null  object \n",
      " 10  name.1                    446176 non-null  object \n",
      " 11  price                     446176 non-null  float64\n",
      " 12  volume24h                 446176 non-null  float64\n",
      " 13  marketCap                 446176 non-null  float64\n",
      " 14  percentChange1h           446176 non-null  float64\n",
      " 15  percentChange24h          446176 non-null  float64\n",
      " 16  percentChange7d           446176 non-null  float64\n",
      " 17  percentChange30d          446176 non-null  float64\n",
      " 18  percentChange60d          446176 non-null  float64\n",
      " 19  percentChange90d          446176 non-null  float64\n",
      " 20  fullyDilluttedMarketCap   446176 non-null  float64\n",
      " 21  marketCapByTotalSupply    446176 non-null  float64\n",
      " 22  dominance                 446176 non-null  float64\n",
      " 23  ytdPriceChangePercentage  446176 non-null  float64\n",
      "dtypes: float64(16), int64(3), object(5)\n",
      "memory usage: 81.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(raw_path)\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24707c4",
   "metadata": {},
   "source": [
    "## 2. Transformação (Transform)\n",
    "\n",
    "Após a extração dos dados, passamos para a etapa de transformação. Nesta fase, realizamos diversas operações para limpar e preparar os dados para análise.\n",
    "\n",
    "Primeiro, são removidas duplicatas e colunas redundantes, garantindo a integridade das informações. Em seguida, convertemos os tipos de dados para formatos apropriados, tratamos valores ausentes e ajustamos colunas de data para o tipo datetime.\n",
    "\n",
    "Além disso, aplicamos a função to_snake_case() para padronizar os nomes das colunas no formato snake_case, assegurando consistência e facilitando a manipulação futura dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9081b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20225 entries, 0 to 427792\n",
      "Data columns (total 23 columns):\n",
      " #   Column                       Non-Null Count  Dtype              \n",
      "---  ------                       --------------  -----              \n",
      " 0   cmc_rank                     20225 non-null  int64              \n",
      " 1   name                         20225 non-null  string             \n",
      " 2   symbol                       20225 non-null  string             \n",
      " 3   market_pair_count            20225 non-null  int64              \n",
      " 4   circulating_supply           20225 non-null  float64            \n",
      " 5   total_supply                 20225 non-null  float64            \n",
      " 6   max_supply                   20225 non-null  float64            \n",
      " 7   is_active                    20225 non-null  bool               \n",
      " 8   last_updated                 20225 non-null  datetime64[ns, UTC]\n",
      " 9   date_added                   20225 non-null  datetime64[ns, UTC]\n",
      " 10  price                        20225 non-null  float64            \n",
      " 11  volume_24h                   20225 non-null  float64            \n",
      " 12  market_cap                   20225 non-null  float64            \n",
      " 13  percent_change_1h            20225 non-null  float64            \n",
      " 14  percent_change_24h           20225 non-null  float64            \n",
      " 15  percent_change_7d            20225 non-null  float64            \n",
      " 16  percent_change_30d           20225 non-null  float64            \n",
      " 17  percent_change_60d           20225 non-null  float64            \n",
      " 18  percent_change_90d           20225 non-null  float64            \n",
      " 19  fully_dillutted_market_cap   20225 non-null  float64            \n",
      " 20  market_cap_by_total_supply   20225 non-null  float64            \n",
      " 21  dominance                    20225 non-null  float64            \n",
      " 22  ytd_price_change_percentage  20225 non-null  float64            \n",
      "dtypes: bool(1), datetime64[ns, UTC](2), float64(16), int64(2), string(2)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def to_snake_case(name: str) -> str:\n",
    "    name = re.sub(r'(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    name = re.sub(r'([a-z0-9])([A-Z])', r'\\1_\\2', name)\n",
    "    name = re.sub(r'([a-zA-Z])(\\d)', r'\\1_\\2', name)\n",
    "\n",
    "    return name.lower()\n",
    "\n",
    "\n",
    "df = df_raw.copy()\n",
    "df = df.drop_duplicates()\n",
    "df = df.drop(columns=[\"name.1\"])\n",
    "\n",
    "df[\"lastUpdated\"] = pd.to_datetime(df[\"lastUpdated\"], errors='coerce')\n",
    "df[\"dateAdded\"] = pd.to_datetime(df[\"dateAdded\"], errors='coerce')\n",
    "df[\"isActive\"] = df[\"isActive\"].astype(bool)\n",
    "df[\"name\"] = df[\"name\"].astype(\"string\")\n",
    "df[\"symbol\"] = df[\"symbol\"].astype(\"string\")\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "df.columns = [to_snake_case(col) for col in df.columns]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "904d8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_cryptocurrencies = Path('../data/silver/silver_currencies_data.csv')\n",
    "df.to_csv(silver_cryptocurrencies, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3c1a9",
   "metadata": {},
   "source": [
    "## 3. Carga (Load)\n",
    "\n",
    "Após o tratamento dos dados, utilizamos as colunas do DataFrame para criar um DDL que define a estrutura da tabela na camada silver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04090623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ddl_table(df: pd.DataFrame, table_name: str) -> str:\n",
    "    dtype_mapping = {\n",
    "        'int64': 'BIGINT',\n",
    "        'float64': 'FLOAT',\n",
    "        'bool': 'BOOLEAN',\n",
    "        'datetime64[ns]': 'TIMESTAMP',\n",
    "        'string': 'VARCHAR(255)',\n",
    "        'object': 'TEXT'\n",
    "    }\n",
    "\n",
    "    ddl = f\"CREATE TABLE IF NOT EXISTS {table_name} (\\n\"\n",
    "    columns = []\n",
    "    \n",
    "    for col, dtype in df.dtypes.items():\n",
    "        sql_type = dtype_mapping.get(str(dtype), 'TEXT')\n",
    "        columns.append(f\"    {col} {sql_type}\")\n",
    "    \n",
    "    ddl += \",\\n\".join(columns)\n",
    "    ddl += \"\\n);\"\n",
    "    \n",
    "    return ddl\n",
    "\n",
    "ddl_path = Path('../data/silver/ddl.sql')\n",
    "\n",
    "with open(ddl_path, 'w') as f:\n",
    "    f.write(create_ddl_table(df, 'currencies_data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0e19d",
   "metadata": {},
   "source": [
    "Com a estrutura do DDL definida, o próximo passo é executar esse comando no banco de dados para criar a tabela. Em seguida, os dados transformados são carregados na tabela recém-criada, garantindo que estejam prontos para análise e consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d962316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "def get_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=os.getenv('DB_HOST','localhost'),\n",
    "            database=os.getenv('POSTGRES_DB','postgres'),\n",
    "            user=os.getenv('POSTGRES_USER','postgres'),\n",
    "            password=os.getenv('POSTGRES_PASSWORD','postgres'),\n",
    "            port=os.getenv('DB_PORT', 5432)\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Failed to connect to the database: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4324d7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully.\n"
     ]
    }
   ],
   "source": [
    "with open(ddl_path, 'r') as f:\n",
    "    ddl_sql = f.read()\n",
    "\n",
    "conn = get_connection()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(ddl_sql)\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "print(\"Table created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d728d9d",
   "metadata": {},
   "source": [
    "Agora basta iterar pelas linhas do DataFrame e inserir os dados na tabela criada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3b347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into currencies_data successfully.\n"
     ]
    }
   ],
   "source": [
    "from psycopg2 import sql\n",
    "\n",
    "def insert_data(df: pd.DataFrame, table_name: str):\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query = sql.SQL(\"INSERT INTO {table} ({fields}) VALUES ({placeholders})\").format(\n",
    "        table=sql.Identifier(table_name),\n",
    "        fields=sql.SQL(', ').join(map(sql.Identifier, df.columns)),\n",
    "        placeholders=sql.SQL(', ').join(sql.Placeholder() * len(df.columns))\n",
    "    )\n",
    "    \n",
    "    for row in df.itertuples(index=False, name=None):\n",
    "        cursor.execute(query, row)\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(f\"Data inserted into {table_name} successfully.\")\n",
    "\n",
    "insert_data(df, 'currencies_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd8adcf1-6539-43ea-949a-ad0cc1413362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRATAMENTO DE DUPLICATAS RAW->SILVER ===\n",
      "Registros brutos: 446176\n",
      "\n",
      "--- ANÁLISE DE DUPLICATAS ---\n",
      "Grupos duplicados encontrados: 19754\n",
      "Total registros duplicados: 445862\n",
      "Exemplo de grupos duplicados:\n",
      "name             lastUpdated              \n",
      "$BABY PEPE COIN  2023-09-04 15:00:00+00:00    23\n",
      "$CROOGE          2023-09-04 15:00:00+00:00     5\n",
      "$LAMBO           2023-09-04 15:00:00+00:00     7\n",
      "$USDEBT          2023-09-04 15:00:00+00:00     6\n",
      "$X               2023-09-04 14:59:00+00:00    18\n",
      "                 2023-09-04 15:00:00+00:00    25\n",
      ".Alpha           2023-09-04 15:00:00+00:00    12\n",
      "00 Token         2023-09-04 14:59:00+00:00    31\n",
      "                 2023-09-04 15:00:00+00:00    25\n",
      "01coin           2023-09-04 15:00:00+00:00    20\n",
      "dtype: int64\n",
      "\n",
      "Exemplo de registros duplicados:\n",
      "                   name               lastUpdated         price  marketCap\n",
      "262701  $BABY PEPE COIN 2023-09-04 15:00:00+00:00  1.761092e-11        0.0\n",
      "269900  $BABY PEPE COIN 2023-09-04 15:00:00+00:00  1.761092e-11        0.0\n",
      "277199  $BABY PEPE COIN 2023-09-04 15:00:00+00:00  1.761092e-11        0.0\n",
      "284598  $BABY PEPE COIN 2023-09-04 15:00:00+00:00  1.761092e-11        0.0\n",
      "292097  $BABY PEPE COIN 2023-09-04 15:00:00+00:00  1.761092e-11        0.0\n",
      "299696  $BABY PEPE COIN 2023-09-04 15:00:00+00:00  1.761092e-11        0.0\n",
      "307395  $BABY PEPE COIN 2023-09-04 15:00:00+00:00  1.761092e-11        0.0\n",
      "315194  $BABY PEPE COIN 2023-09-04 15:00:00+00:00  1.761092e-11        0.0\n",
      "323093  $BABY PEPE COIN 2023-09-04 15:00:00+00:00  1.761092e-11        0.0\n",
      "331092  $BABY PEPE COIN 2023-09-04 15:00:00+00:00  1.761092e-11        0.0\n",
      "\n",
      "--- REMOVENDO DUPLICATAS ---\n",
      "Registros após limpeza: 20068\n",
      "Duplicatas removidas: 426108\n",
      "Duplicatas restantes após limpeza: 0\n",
      "Dados limpos - sem duplicatas!\n",
      "\n",
      "--- CONTINUANDO ETL COM 20068 REGISTROS ---\n",
      "=== VALIDAÇÃO FINAL SILVER ===\n",
      "Total registros silver: 20068\n",
      "Combinações únicas (name + lastUpdated): 20068\n",
      "Dados silver consistentes - sem duplicatas!\n",
      "\n",
      "--- ESTATÍSTICAS SILVER ---\n",
      "Moedas únicas: 9193\n",
      "Timestamps únicos: 4\n",
      "Período: 2023-09-04 14:57:00+00:00 a 2023-09-04 15:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# VERSÃO COMPLETA COM VALIDAÇÕES\n",
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(\"=== TRATAMENTO DE DUPLICATAS RAW->SILVER ===\")\n",
    "print(f\"Registros brutos: {len(df)}\")\n",
    "\n",
    "# 1. Garantir que as colunas-chave estão no formato correto\n",
    "df['name'] = df['name'].astype(str)\n",
    "df['lastUpdated'] = pd.to_datetime(df['lastUpdated'], errors='coerce')\n",
    "\n",
    "# 2. Análise detalhada das duplicatas\n",
    "print(\"\\n--- ANÁLISE DE DUPLICATAS ---\")\n",
    "key_columns = ['name', 'lastUpdated']\n",
    "duplicate_mask = df.duplicated(subset=key_columns, keep=False)\n",
    "duplicate_groups = df[duplicate_mask].groupby(key_columns).size()\n",
    "\n",
    "if len(duplicate_groups) > 0:\n",
    "    print(f\"Grupos duplicados encontrados: {len(duplicate_groups)}\")\n",
    "    print(f\"Total registros duplicados: {duplicate_mask.sum()}\")\n",
    "    print(f\"Exemplo de grupos duplicados:\")\n",
    "    print(duplicate_groups.head(10))\n",
    "    \n",
    "    # Verificar se há diferenças nos dados duplicados\n",
    "    sample_dup = df[duplicate_mask].sort_values(key_columns).head(10)\n",
    "    print(f\"\\nExemplo de registros duplicados:\")\n",
    "    print(sample_dup[['name', 'lastUpdated', 'price', 'marketCap']])\n",
    "else:\n",
    "    print(\"Nenhuma duplicata encontrada.\")\n",
    "\n",
    "print(f\"\\n--- REMOVENDO DUPLICATAS ---\")\n",
    "df_clean = df.sort_values('marketCap', ascending=False).drop_duplicates(subset=key_columns, keep='first')\n",
    "\n",
    "print(f\"Registros após limpeza: {len(df_clean)}\")\n",
    "print(f\"Duplicatas removidas: {len(df) - len(df_clean)}\")\n",
    "\n",
    "# 4. Validação final\n",
    "remaining_duplicates = df_clean.duplicated(subset=key_columns).sum()\n",
    "print(f\"Duplicatas restantes após limpeza: {remaining_duplicates}\")\n",
    "\n",
    "if remaining_duplicates == 0:\n",
    "    print(\"Dados limpos - sem duplicatas!\")\n",
    "else:\n",
    "    print(\"Ainda há duplicatas!\")\n",
    "\n",
    "df = df_clean\n",
    "\n",
    "print(f\"\\n--- CONTINUANDO ETL COM {len(df)} REGISTROS ---\")\n",
    "df = df.drop(columns=[\"name.1\"])\n",
    "\n",
    "\n",
    "print(\"=== VALIDAÇÃO FINAL SILVER ===\")\n",
    "print(f\"Total registros silver: {len(df)}\")\n",
    "\n",
    "# Verificar unicidade\n",
    "unique_combinations = df[['name', 'lastUpdated']].drop_duplicates().shape[0]\n",
    "print(f\"Combinações únicas (name + lastUpdated): {unique_combinations}\")\n",
    "\n",
    "if len(df) == unique_combinations:\n",
    "    print(\"Dados silver consistentes - sem duplicatas!\")\n",
    "else:\n",
    "    print(f\"PROBLEMA: {len(df) - unique_combinations} duplicatas ainda existem\")\n",
    "\n",
    "print(f\"\\n--- ESTATÍSTICAS SILVER ---\")\n",
    "print(f\"Moedas únicas: {df['name'].nunique()}\")\n",
    "print(f\"Timestamps únicos: {df['lastUpdated'].nunique()}\")\n",
    "print(f\"Período: {df['lastUpdated'].min()} a {df['lastUpdated'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2249b-c092-467b-ba38-f1a9cf649c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
